{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQN9CCp5w709",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vectorisation\n",
    "\n",
    "One of the most helpful feature for my past projects (e.g., PDEs, GPs), and one reason that I completely abandoned Matlab.\n",
    "\n",
    "Note: THE vectorisation is not the same as parallelisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7XFMcAD5bAK",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example\n",
    "\n",
    "Suppose that we have two arrays `a` and `b` of shapes `(10, 5, 3, 6)` and `(10, 3, 7, 6)`, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How to do `a @ b` in the way that the multiplication applies to `(5, 3) x (3, 7)` while taking other dimensions as the broadcasting dimension? Eventually, we desire an array of shape `(10, 5, 7, 6)`. \n",
    "\n",
    "How to do so in Numpy/Matlab?\n",
    "\n",
    "(einsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7L8bFendxJF2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgSghCD9xLlM",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def func(x, y):\n",
    "    \"\"\"Arguments x and y have the same shape (2, ).\n",
    "    Return a (2, 2) matrix.\n",
    "    \"\"\"\n",
    "    z = x * y\n",
    "    return np.array([[x[0] ** 2, x[0] * x[1]], \n",
    "                     [np.sin(x[1]), x[0] + x[1]]]) + np.outer(z, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUQs7fdNzHtI",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now if inputs `x` and `y` are of shape `(100, 2)`, how to batch over the first dimension and return a tensor `(100, 2, 2)`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Even more complicated, if the inputs `x` and `y` are of shapes `(100, 2)` and `(300, 2)`, respectively, how to visit over the 100 and 200 and return a tensor `(100, 300, 2, 2)`?\n",
    "\n",
    "Good luck with Matlab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WR5rPSsC1jFr",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How to do these in numpy? As an example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "236-c-z-3DTE",
    "outputId": "2b104a44-72d5-487c-83c4-ee304ba99091",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_vectorized_func = np.vectorize(func, signature='(n),(n)->(n,n)')\n",
    "\n",
    "np_vectorized_func(np.ones((5, 2)), np.ones((5, 2))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sapu4FK42Hy",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Cool! numpy has a concise way to do the vectorisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, please note that `np.vectorize` is merely a syntax sugar of a python loop. It is **not a vectorisation on the computation level**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTQ4ryKo1jH6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The jax implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-O0MieW_77RD",
    "outputId": "1c18ed0f-62a6-4cae-98ef-be8cbeed8290",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def func(x, y):\n",
    "    \"\"\"Arguments x and y are of the same shape (2, ).\n",
    "    Return a (2, 2) matrix.\n",
    "    \"\"\"\n",
    "    z = x * y\n",
    "    return jnp.array([[x[0] ** 2, x[0] * x[1]], \n",
    "                     [jnp.sin(x[1]), x[0] + x[1]]]) + jnp.outer(z, z)\n",
    "\n",
    "jax_vectorized_func = jax.vmap(func, in_axes=[0, 0])\n",
    "\n",
    "jax_vectorized_func(jnp.ones((5, 2)), jnp.ones((5, 2))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kn4_EDXc1jJ7",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Compare speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9TVSWwV8TZm",
    "outputId": "d457add7-cb8b-4b84-ec11-bf088e460ab2",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a = np.ones((10000, 2))\n",
    "%timeit np_vectorized_func(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JFls-TAO8X0t",
    "outputId": "0c48070b-742d-4166-decc-aad9a426c588",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a = jnp.asarray(a)\n",
    "_ = jax_vectorized_func(a, a)\n",
    "%timeit jax_vectorized_func(a, a).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1kWLNZS9Et1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`jax.vmap(func,\n",
    "          in_axes) -> Callable[the same signature as func]`\n",
    "\n",
    "- `func`: the function you want to vectorize\n",
    "- `in_axes`: a tuple/list that indicates the vectorization axes for the arguments of `func`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Recall that our `func(x, y)` takes two `(2, )` arrays as inputs and returns a `(2, 2)` matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To vectorize for `x: (n, 2)` and `y: (n, 2)` for some `n`, use `in_axes=[0, 0]`. Get `(n, ...)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To vectorize for `x: (2, n)` and `y: (n, 2)` for some `n`, use `in_axes=[1, 0]`. Get `(n, ...)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To vectorize for `x: (n, 2)` and `y: (2, )` for some `n`, use `in_axes=[0, None]`. Get `(n, ...)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To vectorize for `x: (m, 2)` and `y: (n, 2)` for some `m, n`. How to do? Use two `vmap` nested!\n",
    "\n",
    "```python\n",
    "jax.vmap(jax.vmap(func, in_axes=[0, None]), in_axes=[None, 0])\n",
    "```\n",
    "\n",
    " Get `(m, n, ...)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yq7skblx1jPT",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "Monte Carlo approximation $\\mathbb{E}[g(X)] \\approx \\frac{1}{N}\\sum^N_{i=1} g(X^i),$ where $X, X^1, X^2, \\ldots \\sim \\mathrm{N}(0, I_2)$ and $ g(X) = \\begin{bmatrix} \\exp(X_1) \\sin(X_2) \\\\ X_1 \\, X_2 + X_1\\end{bmatrix} $\n",
    "\n",
    "```python\n",
    "N = 1000\n",
    "key = ?\n",
    "samples = jax.random.normal(?)\n",
    "\n",
    "def g(x):\n",
    "    return ?\n",
    "    \n",
    "vectorised_g = jax.vmap(?)\n",
    "propogated_samples = vectorised_g(samples)\n",
    "mean_g = jnp.mean(propogated_samples, axis=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oOKuu4STGDQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-cKnpqaP_9go",
    "outputId": "466d6dc1-068c-4e03-d479-8732b2f138d8",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "key = jax.random.PRNGKey(999)\n",
    "samples = jax.random.normal(key, shape=(N, 2))\n",
    "\n",
    "def g(x):\n",
    "    return jnp.array([jnp.exp(x[0]) * jnp.sin(x[1]), \n",
    "                      x[0] * x[1] + x[0]])\n",
    "    \n",
    "vectorised_g = jax.vmap(g, in_axes=[0])\n",
    "\n",
    "propogated_samples = vectorised_g(samples)\n",
    "\n",
    "mean_g = jnp.mean(propogated_samples, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arHygqLKp3AZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "Consider a Matern 3/2 covariance function $C\\colon \\mathbb{R}\\times \\mathbb{R} \\to \\mathbb{R}$ defined by\n",
    "\n",
    "$$\n",
    "C(t, t') = \\sigma^2 \\, \\bigg(1 + \\frac{\\sqrt{3} \\, \\lvert t-t'\\rvert}{\\ell}\\bigg) \\, \\exp\\bigg(-\\frac{\\sqrt{3} \\, \\lvert t-t'\\rvert}{\\ell}\\bigg)\n",
    "$$\n",
    "\n",
    "Say, now we have $T$ data points $t_1, t_2, \\ldots, t_T$, compute the covariance matrix evaluated at the Cartesian $(t_1, t_2, \\ldots, t_T) \\times (t_1, t_2, \\ldots, t_T)$, that is, \n",
    "\n",
    "$$\n",
    "C_{1:T} = \\begin{bmatrix} C(t_1, t_1) & C(t_1, t_2) & \\cdots & C(t_1, t_T) \\\\\n",
    "                                   C(t_2, t_1) & \\ddots & & \\vdots\\\\\n",
    "                                   \\vdots & & & \\vdots\\\\\n",
    "                                   C(t_T, t_1) & \\cdots & \\cdots & C(t_T, t_T)\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "```python\n",
    "def cov_func(t1: float, t2: float, ell: float, sigma: float) -> float:\n",
    "    return ?\n",
    "\n",
    "vectorised_cov_func = jax.vmap(jax.vmap(?), ?)\n",
    "\n",
    "ts = jnp.linspace(0.01, 1, 100)\n",
    "\n",
    "ell, sigma = 0.1, 1.\n",
    "cov_matrix = vectorised_cov_func(ts, ts, ell, sigma)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.contourf(cov_matrix, levels=20)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iPjAFRasjT3",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "szbO28UMsky0",
    "outputId": "0d60f87e-12ca-499d-b7f2-c89a0cb28d09",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def cov_func(t1: float, t2: float, ell: float, sigma: float) -> float:\n",
    "    z = math.sqrt(3) * jnp.abs(t1 - t2) / ell\n",
    "    return sigma ** 2 * (1 + z) * jnp.exp(-z)\n",
    "\n",
    "vectorised_cov_func = jax.vmap(jax.vmap(cov_func, \n",
    "                                        in_axes=[0, None, None, None]), \n",
    "                               in_axes=[None, 0, None, None])\n",
    "\n",
    "# or equivalently\n",
    "# from functools import partial\n",
    "\n",
    "# @partial(jax.vmap, in_axes=[None, 0, None, None])\n",
    "# @partial(jax.vmap, in_axes=[0, None, None, None])\n",
    "# def cov_func(...):\n",
    "#     ...\n",
    "\n",
    "ts = jnp.linspace(0.01, 1, 100)\n",
    "\n",
    "ell, sigma = 0.1, 1.\n",
    "cov_matrix = vectorised_cov_func(ts, ts, ell, sigma)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.contourf(cov_matrix, levels=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Speed comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Numpy implementation 1. Naive implementation with two loops. Do not use this in practice.\n",
    "\n",
    "def np_cov_func(t1, t2):\n",
    "    cov_matrix = np.zeros((ts.size, ts.size))\n",
    "    for i, t1 in enumerate(ts):\n",
    "        for j, t2 in enumerate(ts):\n",
    "            z = math.sqrt(3) * np.abs(t1 - t2) / ell\n",
    "            cov_matrix[i, j] = sigma ** 2 * (1 + z) * np.exp(-z)\n",
    "    return cov_matrix\n",
    "\n",
    "ts_np = np.asarray(ts)\n",
    "%timeit np_cov_func(ts_np, ts_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Numpy implementation 2. Using broadcasting\n",
    "# This is applicable only for limited applications, for example this exercise.\n",
    "\n",
    "def np_cov_func(t1, t2):\n",
    "    z = math.sqrt(3) * np.abs(t1[:, None] - t2[None, :]) / ell\n",
    "    return sigma ** 2 * (1 + z) * np.exp(-z)\n",
    "\n",
    "ts_np = np.asarray(ts)\n",
    "%timeit np_cov_func(ts_np, ts_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7gc_9TaHQHU",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Numpy implementation 3 using scipy cdist\n",
    "\n",
    "import scipy.spatial\n",
    "\n",
    "def np_cov_func(t1, t2):\n",
    "    r = scipy.spatial.distance.cdist(t1, t2, 'euclidean')\n",
    "    z = math.sqrt(3) * r / ell\n",
    "    return sigma ** 2 * (1 + z) * np.exp(-z)\n",
    "\n",
    "ts_np = np.asarray(ts).reshape(-1, 1)\n",
    "%timeit np_cov_func(ts_np, ts_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Y1B-PHSHfWP",
    "outputId": "d9ff66d7-1886-4dd2-ffdd-6a83c03d030a",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# In principle we should not jit vmap which is jitted already, but for some reasons\n",
    "# the jitted vmap is faster than that of non-jitted in my computer\n",
    "f = jax.jit(vectorised_cov_func)\n",
    "\n",
    "f(ts, ts, ell, sigma)\n",
    "\n",
    "%timeit f(ts, ts, ell, sigma).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUnFWWwjIHBR",
    "outputId": "497a4dda-8224-48c1-bc41-968060eb2bee",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vectorised_cov_func(ts, ts, ell, sigma)\n",
    "\n",
    "%timeit vectorised_cov_func(ts, ts, ell, sigma).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoJw4twWukXv",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There is also `jax.pmap`. This for parallelisation across different devices, for example, multiple GPUs/TPUs. See details https://jax.readthedocs.io/en/latest/jax-101/06-parallelism.html."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "jax-clinic-vectorisation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
